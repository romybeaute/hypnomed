{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5Rpb2lAGGn6eAnw6ZyAgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romybeaute/hypnomed/blob/main/all_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load participant list"
      ],
      "metadata": {
        "id": "foM2kb7Hk3GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "\n",
        "!pip install nilearn\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "from scipy.io import savemat\n",
        "from scipy.io import loadmat\n",
        "from nilearn import surface\n",
        "\n",
        "\n",
        "# Function to download and read text file containing subject list\n",
        "def download_and_load_text(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = response.text.splitlines()\n",
        "    return data\n",
        "\n",
        "\n",
        "# URL of the subject list text file\n",
        "excluded_subject = ['sub-32']\n",
        "subject_list_url = 'https://raw.githubusercontent.com/romybeaute/hypnomed/main/diffusion_embedding/scripts_reordered/subject_list.txt'\n",
        "subject_list = [sub for sub in download_and_load_text(subject_list_url)  if sub not in excluded_subject]\n",
        "\n",
        "\n",
        "print(f\"n={len(subject_list)} subjects\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QpXWMDYk2D1",
        "outputId": "ad6aa348-e5bd-43f4-b1e2-e9d592504f5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n=39 subjects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load individual embeddings"
      ],
      "metadata": {
        "id": "1q9TQ9bslMm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    Helper function to download a file from a URL.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # Write the content to a file\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "def load_npy_files(base_url, filenames):\n",
        "    \"\"\"\n",
        "    Downloads and loads multiple .npy files into a list of numpy arrays.\n",
        "    \"\"\"\n",
        "    arrays = []\n",
        "    for filename in filenames:\n",
        "        full_path = f\"{base_url}/{filename}\"\n",
        "        download_file(full_path, filename)  # Download file\n",
        "        array = np.load(filename)  # Load the .npy file\n",
        "        arrays.append(array)\n",
        "        os.remove(filename)  # Clean up the file after loading\n",
        "    return arrays\n",
        "\n",
        "\n",
        "\n",
        "# Base URL for the directory containing .npy files\n",
        "base_url = 'https://raw.githubusercontent.com/romybeaute/hypnomed/main/diffusion_embedding/emb_outputs/emb_output_states'\n",
        "\n",
        "\n",
        "\n",
        "filenames = [\n",
        "    filename\n",
        "    for sub in subject_list if sub not in excluded_subject\n",
        "    for filename in(\n",
        "    f'embedding_dense_emb.{sub}.ses-001.control.npy',\n",
        "    f'embedding_dense_emb.{sub}.ses-001.meditation.npy',\n",
        "    f'embedding_dense_emb.{sub}.ses-001.hypnose.npy' )]\n",
        "\n",
        "# Load all .npy files into a list of numpy arrays\n",
        "all_embeddings = load_npy_files(base_url, filenames)\n",
        "all_embeddings_array = np.stack(all_embeddings, axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "9nvWkanmiry6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realignment of all embeddings : rotate and gather all subjects into a single matrix"
      ],
      "metadata": {
        "id": "3IHSao6pp316"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def run_realign(emb, tar):\n",
        "    realign = []\n",
        "    for i, embed in enumerate(emb):\n",
        "        u, s, v = np.linalg.svd(tar.T.dot(embed), full_matrices=False)\n",
        "        xfm = v.T.dot(u.T)\n",
        "        realign.append(embed.dot(xfm))\n",
        "    return np.array(realign)\n",
        "\n",
        "\n",
        "def load_template(template_base_url):\n",
        "  #load cortex template\n",
        "    cx_url = 'https://raw.githubusercontent.com/romybeaute/hypnomed/main/data/cortex.mat'\n",
        "    download_file(cx_url,'cortex.mat')\n",
        "    cortex = loadmat('cortex.mat')\n",
        "    cortex = np.squeeze(cortex['cortex'])\n",
        "    os.remove('cortex.mat')\n",
        "\n",
        "    template = np.zeros([20484,5])\n",
        "    for grad_id in range(1,6):#for each 5 gradient\n",
        "        left_url = f\"{template_base_url}/hcp.embed.grad_{grad_id}.L.fsa5.func.gii\"\n",
        "        right_url = f\"{template_base_url}/hcp.embed.grad_{grad_id}.R.fsa5.func.gii\"\n",
        "\n",
        "        # Download the Gifti files\n",
        "        left_filename = f\"grad_{grad_id}.L.func.gii\"\n",
        "        right_filename = f\"grad_{grad_id}.R.func.gii\"\n",
        "        download_file(left_url, left_filename)\n",
        "        download_file(right_url, right_filename)\n",
        "\n",
        "        # Load Gifti data\n",
        "        template_L = nib.load(left_filename).darrays[0].data\n",
        "        template_R = nib.load(right_filename).darrays[0].data\n",
        "\n",
        "        # Combine left and right into the template\n",
        "        template[:, grad_id - 1] = np.hstack([template_L, template_R])\n",
        "\n",
        "        # Cleanup the downloaded Gifti files\n",
        "        os.remove(left_filename)\n",
        "        os.remove(right_filename)\n",
        "\n",
        "    # Standardize the template\n",
        "    template = template[cortex, :]  # Apply cortex mask\n",
        "    template = (template - np.mean(template, axis=0)) / np.std(template, axis=0)\n",
        "\n",
        "    return template\n",
        "\n",
        "template_base_url = 'https://raw.githubusercontent.com/romybeaute/hypnomed/main/data/template'\n",
        "template = load_template(template_base_url)\n",
        "template.shape #shape : (n_voxels in template, n gradients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvXSs0KkuSd",
        "outputId": "8aec3027-5963-46d9-c5fd-f44db9ae246b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18715, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_embeddings_array = np.stack(all_embeddings, axis=0)\n",
        "print(all_embeddings_array.shape)\n",
        "\n",
        "realigned = run_realign(all_embeddings_array, template)\n",
        "\n",
        "all_embs = savemat('all_embedding.mat', mdict={'emb': realigned, 'subs': np.array(subject_list, dtype='str')})\n",
        "print('Group matrix succeded and saved in {}'.format('all_embedding.mat'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJqIpFjTuDVi",
        "outputId": "f4b6f86a-ae83-4008-f746-3050dad5d982"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(117, 18715, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "f = loadmat('all_embedding.mat')\n",
        "print('Embeddings shape:', f['emb'].shape)\n",
        "print(f'n subjects =', len(f['subs']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7eEighIusim",
        "outputId": "e9ae1de1-eb06-4a0e-94e6-37932c005636"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (117, 18715, 5)\n",
            "n subjects = 39\n"
          ]
        }
      ]
    }
  ]
}